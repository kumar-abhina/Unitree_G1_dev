# How does it work? ğŸ¤”

The setup consists of two Python scripts and **GStreamer** glue code.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    USB3     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     RTP/UDP      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ D435i  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚ Jetson NX /  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚  Laptop /    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  jetson_re.. â”‚  5600  5602      â”‚receive_..gst â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      (H.264 / RGB)     (H.264 / depth-colormap)
```

## 1. `jetson_realsense_stream.py`

Runs **on the Jetson NX** inside the robot.

1. Uses **`pyrealsense2`** to open the camera with the resolution & FPS you specify.
2. Captures two streams every frame:
   â€¢ `rs.stream.color` â†’ BGR 8-bit image.  
   â€¢ `rs.stream.depth` â†’ 16-bit millimetre depth image.
3. The depth frame is optionally run through a **temporal filter** to reduce noise and is then colour-mapped to an 8-bit BGR image using OpenCV (Plasma LUT).  This makes it easy to encode with standard video codecs.
4. Two **`GstAppSrc`** elements act as entrypoints into a GStreamer pipeline:

   ```text
   RGB  : AppSrc â†’ videoconvert â†’ nvvidconv â†’ nvv4l2h264enc â†’ rtph264pay â†’ udpsink 5600
   Depth: AppSrc â†’ videoconvert â†’ nvvidconv â†’ nvv4l2h264enc â†’ rtph264pay â†’ udpsink 5602
   ```

   *The Jetsonâ€™s hardware H.264 encoder (`nvv4l2h264enc`) keeps CPU usage low.*

5. Result: **Two RTP streams** leave the Jetson over the network:
   â€¢ **5600/UDP** â€“ H.264 encoded RGB
   â€¢ **5602/UDP** â€“ H.264 encoded colourised depth

## 2. `receive_realsense_gst.py`

Runs **on your PC**.

1. Builds two **GStreamer pipelines** that start with `udpsrc` and end with an **`GstAppSink`**:

   ```text
   udpsrc â†’ rtph264depay â†’ avdec_h264 â†’ videoconvert â†’ BGR â†’ AppSink
   ```

2. Buffers pulled from the sinks are converted to NumPy arrays, stacked side-by-side and displayed with `cv2.imshow()`.

3. If you need the *raw* 16-bit depth instead of a colour-mapped preview see the alternative script [`receive_realsense_stream.py`](../receive_realsense_stream.py) that uses OpenCVâ€™s GStreamer backend and RFC-4175 raw video.

## 3. Network considerations

â€¢ A wired Gigabit connection easily copes with the combined 6â€“8 Mbit/s bitrate.  
â€¢ On Wi-Fi lower latencies can be achieved by keeping both devices on the same AP and 5 GHz band.  
â€¢ The receiver trusts frames to arrive in order; avoid WAN/VPN links that may re-order or drop UDP traffic.

## 4. Customising resolution / FPS / bitrate

*Jetson â†’* Supply `--width`, `--height`, `--fps` to change the camera configuration.  
*Encoder settings â†’* Adjust the `bitrate=` property of the two `nvv4l2h264enc` instances inside `jetson_realsense_stream.py` if you need higher quality.
